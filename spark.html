<!DOCTYPE html>
<html>
<head>
    <title>PySpark DataFrame Examples</title>
    <style>
        body { font-family: Arial, sans-serif; }
        pre { background-color: #f4f4f4; padding: 10px; border-left: 4px solid #333; overflow-x: auto; }
        hr { margin: 20px 0; border: none; border-top: 2px solid #333; }
    </style>
</head>
<body>
    <h1>PySpark Basics - Databricks</h1>
    
    <h2>Creating a Spark Session</h2>
    <pre>
from pyspark.sql import SparkSession

# Create Spark session
spark = SparkSession.builder.appName("Databricks PySpark Guide").getOrCreate()
    </pre>
    
    <h2>Creating DataFrames</h2>
    <pre>
from pyspark.sql import Row

# Creating a DataFrame manually
data = [Row(id=1, name='Alice', amount=100.50), Row(id=2, name='Bob', amount=200.75)]
df = spark.createDataFrame(data)
df.show()
    </pre>
    
    <h2>Reading Delta Tables</h2>
    <pre>
# Read a Delta table into a DataFrame
df = spark.read.format("delta").table("sales")
df.show()
    </pre>
    
    <h2>Transforming DataFrames</h2>
    <pre>
from pyspark.sql.functions import col

# Filter and select specific columns
df_filtered = df.filter(col("amount") > 100).select("name", "amount")
df_filtered.show()
    </pre>
    
    <h2>Writing DataFrames to Delta Tables</h2>
    <pre>
# Write a DataFrame to a Delta table
df.write.format("delta").mode("append").saveAsTable("sales")
    </pre>
    
    <h2>Updating Delta Tables</h2>
    <pre>
from delta.tables import DeltaTable

delta_table = DeltaTable.forName(spark, "sales")
delta_table.update(
    condition=col("id") == 1,
    set={"amount": col("amount") * 1.1}  # Increase amount by 10%
)
    </pre>
    
    <h2>Deleting Data from Delta Tables</h2>
    <pre>
# Delete records from Delta table
delta_table.delete(col("id") == 2)
    </pre>
    
    <h2>Optimizing Delta Tables</h2>
    <pre>
# Optimize Delta table to improve query performance
spark.sql("OPTIMIZE sales ZORDER BY order_date")
    </pre>
    
    <hr>
    
    <h1>Beginner and Intermediate PySpark DataFrame Examples</h1>
    
    <h2>Creating a Simple DataFrame</h2>
    <pre>
data = [("Alice", 25), ("Bob", 30), ("Charlie", 35)]
columns = ["Name", "Age"]
df = spark.createDataFrame(data, columns)
df.show()
    </pre>
    
    <h2>Creating a DataFrame from JSON</h2>
    <pre>
data = [{"Name": "Alice", "Age": 25}, {"Name": "Bob", "Age": 30}]
df = spark.read.json(spark.spark
